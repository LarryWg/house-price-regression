{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6f5e160d",
      "metadata": {},
      "source": [
        "# Push datasets and model to AWS S3\n",
        "\n",
        "**Prerequisites**\n",
        "- AWS CLI configured (`aws configure`) or env vars `AWS_ACCESS_KEY_ID` / `AWS_SECRET_ACCESS_KEY`\n",
        "- Bucket `larry-house-price-regression-data` exists in `ca-central-1`\n",
        "- IAM user/role has **s3:PutObject** (and s3:GetObject if you want to read back) on the bucket\n",
        "\n",
        "**If you get AccessDenied:** attach an IAM policy that allows `s3:PutObject` and `s3:GetObject` on `arn:aws:s3:::larry-house-price-regression-data/*`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e9e1ca76",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading /Users/larry/house-price-regression/data/processed/train_engineered.csv to s3://larry-house-price-regression-data/processed/train_engineered.csv...\n"
          ]
        },
        {
          "ename": "S3UploadFailedError",
          "evalue": "Failed to upload /Users/larry/house-price-regression/data/processed/train_engineered.csv to larry-house-price-regression-data/processed/train_engineered.csv: An error occurred (AccessDenied) when calling the CreateMultipartUpload operation: User: arn:aws:iam::834000420058:user/Larry is not authorized to perform: s3:PutObject on resource: \"arn:aws:s3:::larry-house-price-regression-data/processed/train_engineered.csv\" because no identity-based policy allows the s3:PutObject action",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAccessDenied\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/boto3/s3/transfer.py:452\u001b[39m, in \u001b[36mS3Transfer.upload_file\u001b[39m\u001b[34m(self, filename, bucket, key, callback, extra_args)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m     \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# client error.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/s3transfer/futures.py:111\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[32m    109\u001b[39m     \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[32m    110\u001b[39m     \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/s3transfer/futures.py:287\u001b[39m, in \u001b[36mTransferCoordinator.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/s3transfer/tasks.py:142\u001b[39m, in \u001b[36mTask.__call__\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transfer_coordinator.done():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/s3transfer/tasks.py:165\u001b[39m, in \u001b[36mTask._execute_main\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    163\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuting task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with kwargs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs_to_display\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m return_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# If the task is the final task, then set the TransferFuture's\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# value to the return value from main().\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/s3transfer/tasks.py:351\u001b[39m, in \u001b[36mCreateMultipartUploadTask._main\u001b[39m\u001b[34m(self, client, bucket, key, extra_args)\u001b[39m\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# Create the multipart upload.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_multipart_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_args\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m upload_id = response[\u001b[33m'\u001b[39m\u001b[33mUploadId\u001b[39m\u001b[33m'\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/botocore/client.py:602\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/botocore/client.py:1078\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1077\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mAccessDenied\u001b[39m: An error occurred (AccessDenied) when calling the CreateMultipartUpload operation: User: arn:aws:iam::834000420058:user/Larry is not authorized to perform: s3:PutObject on resource: \"arn:aws:s3:::larry-house-price-regression-data/processed/train_engineered.csv\" because no identity-based policy allows the s3:PutObject action",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mS3UploadFailedError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Processed datasets (from feature engineering / notebook 02)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43mupload_to_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_engineered.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprocessed/train_engineered.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m upload_to_s3(DATA_DIR / \u001b[33m\"\u001b[39m\u001b[33meval_engineered.csv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mprocessed/eval_engineered.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Model: try both names used in this repo\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mupload_to_s3\u001b[39m\u001b[34m(local_path, s3_key)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUploading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to s3://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms3_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[43ms3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Done.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/boto3/s3/inject.py:175\u001b[39m, in \u001b[36mupload_file\u001b[39m\u001b[34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[32m    141\u001b[39m \n\u001b[32m    142\u001b[39m \u001b[33;03mUsage::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m \u001b[33;03m    transfer.\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/house-price-regression/.venv/lib/python3.11/site-packages/boto3/s3/transfer.py:458\u001b[39m, in \u001b[36mS3Transfer.upload_file\u001b[39m\u001b[34m(self, filename, bucket, key, callback, extra_args)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# client error.\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m458\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m S3UploadFailedError(\n\u001b[32m    459\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to upload \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    460\u001b[39m     )\n",
            "\u001b[31mS3UploadFailedError\u001b[39m: Failed to upload /Users/larry/house-price-regression/data/processed/train_engineered.csv to larry-house-price-regression-data/processed/train_engineered.csv: An error occurred (AccessDenied) when calling the CreateMultipartUpload operation: User: arn:aws:iam::834000420058:user/Larry is not authorized to perform: s3:PutObject on resource: \"arn:aws:s3:::larry-house-price-regression-data/processed/train_engineered.csv\" because no identity-based policy allows the s3:PutObject action"
          ]
        }
      ],
      "source": [
        "import boto3\n",
        "from pathlib import Path\n",
        "\n",
        "from botocore.exceptions import ClientError\n",
        "\n",
        "bucket = \"larry-house-price-regression-data\"\n",
        "region = \"ca-central-1\"\n",
        "\n",
        "# Project root: works when cwd is project root or notebooks/\n",
        "PROJECT_ROOT = Path.cwd() if (Path.cwd() / \"data\").exists() else Path.cwd().parent\n",
        "DATA_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
        "MODEL_DIR = PROJECT_ROOT / \"models\"\n",
        "\n",
        "s3 = boto3.client(\"s3\", region_name=region)\n",
        "\n",
        "\n",
        "def upload_to_s3(local_path: Path, s3_key: str) -> bool:\n",
        "    \"\"\"Upload a file to S3. Returns True on success, False on skip/error.\"\"\"\n",
        "    if not local_path.exists():\n",
        "        print(f\"File {local_path} does not exist. Skipping upload.\")\n",
        "        return False\n",
        "    print(f\"Uploading {local_path} to s3://{bucket}/{s3_key}...\")\n",
        "    try:\n",
        "        s3.upload_file(str(local_path), bucket, s3_key)\n",
        "        print(f\"  Done.\")\n",
        "        return True\n",
        "    except ClientError as e:\n",
        "        if e.response[\"Error\"][\"Code\"] == \"AccessDenied\":\n",
        "            print(\n",
        "                \"  AccessDenied: Your IAM user/role needs s3:PutObject on this bucket.\\n\"\n",
        "                \"  Example policy (attach to user/role):\\n\"\n",
        "                '  {\"Effect\": \"Allow\", \"Action\": [\"s3:PutObject\", \"s3:GetObject\"], '\n",
        "                f'\"Resource\": \"arn:aws:s3:::{bucket}/*\"}}'\n",
        "            )\n",
        "        else:\n",
        "            print(f\"  Error: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# Processed datasets (from feature engineering / notebook 02)\n",
        "upload_to_s3(DATA_DIR / \"train_engineered.csv\", \"processed/train_engineered.csv\")\n",
        "upload_to_s3(DATA_DIR / \"eval_engineered.csv\", \"processed/eval_engineered.csv\")\n",
        "\n",
        "# Model: try both names used in this repo\n",
        "upload_to_s3(MODEL_DIR / \"xgb_best_model.pkl\", \"models/xgb_best_model.pkl\")\n",
        "upload_to_s3(MODEL_DIR / \"xgb_model.pkl\", \"models/xgb_model.pkl\")\n",
        "\n",
        "# Encoders (needed for inference)\n",
        "upload_to_s3(MODEL_DIR / \"freq_encoder.pkl\", \"models/freq_encoder.pkl\")\n",
        "upload_to_s3(MODEL_DIR / \"target_encoder.pkl\", \"models/target_encoder.pkl\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.11.14)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
